{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%pip` not found (But line magic `%pip` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%%pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHRONIC ANAL FISSURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PAIN ON DEFACATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>UNDER EVALUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LEFT EAR PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UNDER EVALUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>PAIN ABDOMEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>PALPITATIONS -EPISODIC X 10 DAYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HYPERTENSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>FOLLOW UP CASE OF FIBRO ADENOSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>WITH LUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>B/L CYCLIC MASTALGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>hearing loss under evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>b/l reduced hearing sensitivity for 4 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>fuc gall stone induced pancreatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>symptomatically relieved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>fuc gall stone induced pancreatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>UNDER EVALUATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>LEFT EAR DISCHARGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>?b/l renal calculi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>b/l flank pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S No                                     Symptoms\n",
       "0      1                         CHRONIC ANAL FISSURE\n",
       "1      2                           PAIN ON DEFACATION\n",
       "2      3                             UNDER EVALUATION\n",
       "3      4                                LEFT EAR PAIN\n",
       "4      5                             UNDER EVALUATION\n",
       "5      6                                 PAIN ABDOMEN\n",
       "6      7             PALPITATIONS -EPISODIC X 10 DAYS\n",
       "7      8                                 HYPERTENSION\n",
       "8      9             FOLLOW UP CASE OF FIBRO ADENOSIS\n",
       "9     10                                    WITH LUMP\n",
       "10    11                         B/L CYCLIC MASTALGIA\n",
       "11    12                hearing loss under evaluation\n",
       "12    13  b/l reduced hearing sensitivity for 4 years\n",
       "13    14          fuc gall stone induced pancreatitis\n",
       "14    15                     symptomatically relieved\n",
       "15    16          fuc gall stone induced pancreatitis\n",
       "16    17                             UNDER EVALUATION\n",
       "17    18                           LEFT EAR DISCHARGE\n",
       "18    19                           ?b/l renal calculi\n",
       "19    20                               b/l flank pain"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"symptoms.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chronic anal fissure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pain on defacation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>under evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>left ear pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>under evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>pain in lower back x 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>sacroilitis left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>ulcer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>uljhan ghabrahat x 2months  neend na aana x 3days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>u/e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S No                                           Symptoms\n",
       "0       1                               chronic anal fissure\n",
       "1       2                                 pain on defacation\n",
       "2       3                                   under evaluation\n",
       "3       4                                      left ear pain\n",
       "4       5                                   under evaluation\n",
       "..    ...                                                ...\n",
       "995   996                        pain in lower back x 1 year\n",
       "996   997                                   sacroilitis left\n",
       "997   998                                              ulcer\n",
       "998   999  uljhan ghabrahat x 2months  neend na aana x 3days\n",
       "999  1000                                                u/e\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change in lower case\n",
    "df['Symptoms']=df['Symptoms'].astype(str)\n",
    "df[\"Symptoms\"] = df['Symptoms'].apply(lambda x:x.lower())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: fever headache for 20 days\n",
      "Embedding: [-3.37383062e-01 -1.72585085e-01  6.13100752e-02  1.05608262e-01\n",
      "  6.83006465e-01  1.22509755e-01 -1.50762782e-01  1.51947245e-01\n",
      " -1.75441220e-01 -5.96649766e-01 -1.81785658e-01  2.42729098e-01\n",
      "  2.35890344e-01  1.09404258e-01  1.51140854e-01  2.62060314e-01\n",
      "  1.13357671e-01 -6.06959641e-01  1.92453694e-02  8.69150758e-02\n",
      " -6.47365034e-01  4.81429905e-01 -3.44495803e-01  5.82445003e-02\n",
      " -1.88052490e-01  7.63156354e-01  8.13210547e-01  1.42707929e-01\n",
      " -4.98109274e-02  5.67465425e-01  3.16799372e-01 -6.08237684e-01\n",
      " -6.44787908e-01  1.14562893e-02  3.31757545e-01 -1.39980251e-02\n",
      " -2.87972450e-01  1.96022585e-01  3.73038463e-02  6.29129827e-01\n",
      " -1.76021621e-01  5.08565068e-01  8.05818196e-03 -5.79347014e-01\n",
      "  5.44488490e-01  5.91766417e-01 -2.92074773e-02  4.14447963e-01\n",
      "  2.04684258e-01  4.04682666e-01 -6.01211607e-01 -3.93664390e-01\n",
      "  1.86209515e-01  8.24444115e-01 -2.63693593e-02  3.96104723e-01\n",
      " -7.28555322e-01  6.83775321e-02 -7.18120396e-01  3.21222454e-01\n",
      " -2.64674455e-01 -1.83632493e-01  1.04020607e+00 -1.95037022e-01\n",
      "  8.80116299e-02 -3.00246000e-01  3.07391256e-01 -3.84817980e-02\n",
      "  5.96590459e-01  2.07749531e-01  7.74064437e-02 -2.47517690e-01\n",
      " -2.75315821e-01 -3.86960834e-01  2.07746148e-01 -4.25520182e-01\n",
      "  2.68366225e-02 -3.08620393e-01 -1.91867694e-01  4.85980436e-02\n",
      "  4.08844709e-01  4.32060570e-01  2.45819286e-01  2.30091557e-01\n",
      " -2.99036592e-01 -1.78839609e-01  3.74825895e-01  5.99755883e-01\n",
      "  7.85735324e-02  2.56042404e-04  5.89431643e-01  5.38445171e-03\n",
      " -1.18793674e-01 -1.82569310e-01  3.53968829e-01  1.71783671e-01\n",
      " -4.93527830e-01  3.73984098e-01 -4.77066487e-01  5.98592818e-01\n",
      " -6.48603439e-01 -9.08415496e-01 -7.98509479e-01  1.53744414e-01\n",
      "  2.80707538e-01  3.49396735e-01  5.31484306e-01  2.28757143e-01\n",
      " -3.65034729e-01 -4.79184180e-01  1.57305822e-01  6.49477124e-01\n",
      "  3.67104501e-01 -2.33250111e-01  3.05148035e-01 -4.49407578e-01\n",
      " -2.95141429e-01  2.38609537e-01 -4.08938825e-01  3.85102659e-01\n",
      "  3.67929369e-01  1.71411872e-01 -2.34163895e-01 -2.29926363e-01\n",
      "  3.79043192e-01  4.31431919e-01  4.84127462e-01 -3.41859341e-01\n",
      "  4.14805084e-01 -1.47436664e-01  1.46466210e-01 -6.05224781e-02\n",
      " -1.05918340e-01  5.58914304e-01 -1.43553510e-01  5.96201420e-01\n",
      "  3.77923548e-01 -3.12342611e-03  2.88654327e-01 -5.88338912e-01\n",
      " -2.92582184e-01 -1.19660750e-01 -3.86624366e-01 -3.62684995e-01\n",
      "  7.55386412e-01  2.68372297e-02  6.33549273e-01 -1.76134616e-01\n",
      " -2.27837056e-01 -9.25185680e-01  4.16956544e-02  1.28041059e-01\n",
      "  2.11510494e-01  7.66005814e-01  2.78089464e-01  4.38268110e-02\n",
      "  3.54388952e-01 -1.70030355e-01  3.53494972e-01 -3.80283058e-01\n",
      " -3.27350825e-01 -1.63548440e-02 -7.71823004e-02 -1.55024201e-01\n",
      " -1.73487663e-01  6.60130680e-01 -1.58051252e-01 -9.13348868e-02\n",
      "  1.30868003e-01  3.40877116e-01 -6.89576089e-01 -2.31212288e-01\n",
      "  2.06821278e-01  2.66477823e-01 -1.71133445e-03  4.95508701e-01\n",
      " -3.52694988e-01 -3.55463177e-01  1.54421329e-01 -2.71186829e-01\n",
      "  7.01694608e-01 -5.30335829e-02 -9.70256794e-03  5.51304042e-01\n",
      "  2.41821527e-01 -3.22572887e-01  3.68012041e-01  4.13462780e-02\n",
      " -1.17459573e-01 -5.83193183e-01 -5.03502488e-01 -5.12603819e-01\n",
      "  5.22451520e-01  6.09523237e-01  2.21031159e-02 -1.49962291e-01\n",
      " -2.78542966e-01 -3.47189486e-01  2.69624501e-01  1.66034088e-01\n",
      " -1.43771529e-01  3.45024735e-01 -4.88542289e-01  2.73555249e-01\n",
      "  7.54748166e-01 -2.35131040e-01 -1.77376240e-01 -4.00919825e-01\n",
      " -7.22313464e-01 -4.55219716e-01  5.54311812e-01  1.11767328e+00\n",
      "  8.07143629e-01  1.25578120e-01  3.07065427e-01  3.04867744e-01\n",
      " -3.78763020e-01 -6.28018379e-01  3.71449664e-02  2.24324465e-01\n",
      " -3.41109365e-01  3.62580836e-01 -4.38067913e-01 -1.46417469e-01\n",
      " -1.01446472e-01 -2.71398008e-01 -1.03854549e+00  2.61609823e-01\n",
      "  1.52484655e-01  6.20659925e-02 -4.75592077e-01  1.63532531e+00\n",
      "  1.50540426e-01  3.34042937e-01  3.41871530e-01 -3.07494670e-01\n",
      " -9.90561485e-01 -7.88957253e-02  2.75495946e-02  6.84553564e-01\n",
      " -3.95172060e-01  4.98712689e-01  5.29603139e-02  2.74838924e-01\n",
      " -6.53267682e-01  9.15426791e-01  7.13647008e-02 -5.25280237e-01\n",
      "  3.51526886e-01  4.45422605e-02  4.56038684e-01 -4.61660564e-01\n",
      " -7.85607159e-01 -3.38019043e-01  5.49243810e-03  2.25125790e-01\n",
      "  4.23631072e-02 -1.27221078e-01 -2.94705302e-01  4.27415401e-01\n",
      " -3.38616699e-01 -5.59684873e-01  1.43097982e-01 -2.90724039e-02\n",
      " -1.77898630e-01  2.76633352e-01  6.86397254e-01 -4.41387221e-02\n",
      " -1.74247071e-01  4.21959400e-01 -1.22678638e-01 -3.88197958e-01\n",
      "  8.47619623e-02  4.75690901e-01 -2.32222795e-01 -2.38663837e-01\n",
      "  5.61567619e-02  2.53379077e-01 -2.40505747e-02 -9.00527894e-01\n",
      " -3.17701638e-01 -2.92508602e-01  4.90756571e-01 -3.24408561e-01\n",
      "  8.65326598e-02 -8.51728559e-01 -2.19719067e-01 -3.18683535e-01\n",
      "  1.51991963e-01  3.09564829e-01 -1.16501562e-01 -2.89857574e-02\n",
      "  1.14625764e+00 -4.09907967e-01 -2.09988263e-02  1.93726450e-01\n",
      " -7.29814708e-01 -3.22291911e-01 -1.78475723e-01 -3.55521947e-01\n",
      " -1.40849864e-02  2.95898587e-01  2.82164633e-01 -5.27227938e-01\n",
      " -4.90842104e-01 -2.40681797e-01 -3.40388790e-02 -6.83696449e-01\n",
      " -3.16806078e-01 -4.15906101e-01 -8.94024000e-02 -3.88493799e-02\n",
      " -3.53059322e-01  4.56839085e-01  3.89326252e-02  4.94927764e-02\n",
      " -1.91244334e-01  8.06346118e-01  3.25195134e-01 -3.10923129e-01\n",
      "  8.60038817e-01 -9.43053737e-02 -1.29255578e-01 -1.95253953e-01\n",
      " -1.41303793e-01 -4.79108751e-01 -8.42703283e-01  5.18187024e-02\n",
      "  1.44021541e-01  3.89108270e-01  2.40747243e-01  4.06924874e-01\n",
      "  3.85929018e-01  2.18376994e-01 -1.13608479e+00 -1.71551317e-01\n",
      " -4.82523501e-01  1.53698429e-01 -2.28492334e-01  4.17413302e-02\n",
      "  4.26448494e-01 -1.29014002e-02  1.61198109e-01 -8.53180960e-02\n",
      "  6.12386048e-01 -3.85728270e-01  1.37591109e-01  5.84919490e-02\n",
      " -3.11774582e-01 -9.73409176e-01 -7.21083999e-01  2.39978041e-02\n",
      "  2.78005451e-02 -1.18302710e-01 -1.83310248e-02 -3.02037627e-01\n",
      " -4.62470978e-01  8.28635618e-02  6.14350200e-01  1.64241344e-01\n",
      " -1.41263708e-01  1.21704899e-01  2.37733647e-01 -3.88313502e-01\n",
      "  1.48928957e-02 -7.67286301e-01  1.98070154e-01  1.20607421e-01\n",
      " -2.95731455e-01  3.12437173e-02 -1.23162329e-01  2.58098990e-01\n",
      "  4.68747914e-01  2.05594450e-01  1.04365929e-03  1.31177055e-02\n",
      "  3.61153781e-02  5.19783676e-01 -2.67232031e-01 -6.24145448e-01\n",
      " -6.30059838e-01  4.31108445e-01 -8.12852025e-01 -1.34067312e-01]\n",
      "\n",
      "Sentence: fever and headache 1 day\n",
      "Embedding: [-4.79436368e-01 -2.89892137e-01 -1.37464866e-01  5.69466710e-01\n",
      "  6.77649796e-01 -2.00662479e-01  1.36999264e-01 -1.01356171e-01\n",
      " -1.32058427e-01 -4.32379454e-01 -1.15851521e-01 -7.61962682e-02\n",
      " -2.69147009e-02  4.26428616e-02  2.03409791e-02 -1.27076671e-01\n",
      "  2.42174357e-01 -1.16805530e+00 -5.55189587e-02 -2.64074542e-02\n",
      " -9.42125618e-01  3.97774726e-01 -6.50704026e-01 -1.84970811e-01\n",
      " -2.48606724e-04  3.44082922e-01  5.94220221e-01  1.57173742e-02\n",
      " -2.33914349e-02  7.49186203e-02  3.29472870e-01 -4.54478055e-01\n",
      " -3.20876122e-01  4.38879468e-02  3.08733672e-01  5.69469668e-02\n",
      "  4.12052184e-01  1.42801970e-01 -8.01659673e-02  7.59623230e-01\n",
      " -3.04972321e-01  1.83435664e-01  2.36403450e-01 -5.18240213e-01\n",
      "  3.82001460e-01  4.33998615e-01 -1.56356841e-01  9.27657962e-01\n",
      "  9.05695736e-01  4.17070299e-01 -5.76373577e-01 -3.26305211e-01\n",
      "  7.54679069e-02  6.06009305e-01 -1.49923176e-01  6.83885694e-01\n",
      " -7.26657450e-01  5.14594197e-01 -7.89435565e-01  4.71500605e-01\n",
      " -4.66835409e-01 -1.41270354e-01  7.93915749e-01  6.39163926e-02\n",
      "  5.57349622e-01 -4.29038912e-01 -4.51901220e-02 -5.44920973e-02\n",
      "  6.69264197e-01  3.24595690e-01  1.45236701e-01  7.56288990e-02\n",
      " -2.07466483e-01 -2.97655970e-01  2.81073868e-01 -1.45209283e-01\n",
      " -2.49967203e-01 -2.92204678e-01  1.14249304e-01  2.30124846e-01\n",
      " -2.29370564e-01  1.55965015e-01  1.67313457e-01 -7.21715242e-02\n",
      " -1.46672474e-02  9.31374654e-02  1.14739232e-01  6.03286266e-01\n",
      "  2.74091095e-01  1.33260071e-01  5.68358481e-01 -8.39295238e-02\n",
      "  1.12339277e-02 -2.74271995e-01  6.47994459e-01  1.12219825e-01\n",
      " -4.26843673e-01  3.47019404e-01 -5.35197675e-01  5.81397235e-01\n",
      " -4.45612669e-01 -1.09732032e+00 -7.71452487e-01  7.40177333e-01\n",
      "  5.71434975e-01  2.58233845e-01  3.63521069e-01 -2.07099706e-01\n",
      " -1.46609157e-01 -5.88218570e-01  1.96390554e-01  3.72397810e-01\n",
      "  2.54517257e-01 -3.87985975e-01  4.22542065e-01 -2.65346199e-01\n",
      "  2.28106707e-01  2.42637351e-01 -6.97904408e-01  2.28444174e-01\n",
      "  2.10651010e-01  1.96901336e-01 -1.23238213e-01 -4.82904106e-01\n",
      "  1.64243355e-01  3.28776658e-01  4.58414614e-01  3.00279520e-02\n",
      "  1.29077613e-01  2.63245285e-01  9.37147290e-02  5.85100465e-02\n",
      "  2.80836783e-02  2.43399501e-01  9.20121670e-02  4.09583837e-01\n",
      "  3.69013995e-01  9.24789459e-02  4.46632683e-01 -7.03518450e-01\n",
      " -2.05840141e-01  8.04709122e-02 -5.05902112e-01 -5.74085593e-01\n",
      "  7.84946740e-01  1.10291801e-01 -1.41730709e-02 -2.15039819e-01\n",
      " -2.34915018e-01 -8.09878767e-01 -1.00671992e-01  6.46451861e-02\n",
      "  1.87835231e-01  7.24478304e-01  1.06596150e-01  3.65154564e-01\n",
      "  8.84787589e-02 -1.73797719e-02  3.49489659e-01 -4.65769976e-01\n",
      " -3.65488917e-01  2.77469099e-01 -4.55369741e-01  2.54680187e-01\n",
      "  7.71431550e-02  4.51370418e-01 -5.64569756e-02  1.01634279e-01\n",
      " -2.29936972e-01  6.08757436e-02 -6.64808273e-01 -1.67145178e-01\n",
      "  2.75927596e-02  3.08730453e-01  7.07458705e-04  4.88643497e-01\n",
      " -2.43173033e-01 -4.71566737e-01 -1.41338825e-01 -7.18331784e-02\n",
      "  1.13014650e+00 -5.65574691e-02 -1.92211494e-01  6.14489138e-01\n",
      "  3.89397830e-01 -1.09251611e-01  3.62170786e-01  2.87270069e-01\n",
      " -2.18517154e-01 -4.29596215e-01 -4.64143187e-01 -2.42599174e-01\n",
      "  9.92166176e-02  4.37767565e-01  9.64782387e-02 -2.00425953e-01\n",
      " -6.26627505e-01 -2.51787186e-01  3.24822366e-01 -4.42447476e-02\n",
      " -8.06388855e-02  2.80777872e-01 -4.96391237e-01  2.98615426e-01\n",
      "  7.18574643e-01 -4.31381851e-01 -5.15376866e-01 -1.47183210e-01\n",
      " -5.76516271e-01 -2.07857639e-01  8.45565915e-01  1.04164577e+00\n",
      "  6.25709116e-01  8.80947262e-02  2.21303478e-01  3.82581979e-01\n",
      " -4.04194504e-01 -5.23781888e-02 -3.94339766e-03  3.08718145e-01\n",
      " -2.19856277e-01  9.14329067e-02 -1.28663033e-01 -3.13805521e-01\n",
      " -8.32608789e-02 -1.93259437e-02 -8.16479385e-01  3.78905207e-01\n",
      "  1.18221097e-01  4.45111036e-01 -3.40252072e-01  1.29492104e+00\n",
      "  2.31883317e-01  6.87639236e-01  4.58798259e-01 -2.26499692e-01\n",
      " -1.24043941e+00  2.68492289e-02  1.57060727e-01  3.15496288e-02\n",
      "  6.94526210e-02  5.96450269e-01  2.04844307e-02  5.28550208e-01\n",
      " -7.77320027e-01  2.38653108e-01 -4.35798407e-01 -3.72182608e-01\n",
      "  7.69234523e-02  2.60154694e-01  1.78136081e-01 -1.63131312e-01\n",
      " -3.38807881e-01 -3.18797022e-01 -1.57231316e-01  5.44540286e-01\n",
      "  1.60171628e-01 -1.92007020e-01  1.07451417e-01  3.37129444e-01\n",
      " -2.22734049e-01 -7.05947399e-01  3.23343664e-01 -2.54062680e-03\n",
      "  7.41821602e-02  3.87268037e-01  6.85416281e-01  2.97526449e-01\n",
      " -6.13545254e-02  1.02252580e-01 -1.77376971e-01 -3.04733753e-01\n",
      " -1.19551942e-01  3.60307485e-01 -2.31788978e-01 -3.59561712e-01\n",
      " -9.87758264e-02  3.93286288e-01 -5.80900498e-02 -7.77773321e-01\n",
      " -3.64472628e-01 -5.74246824e-01 -1.28112361e-01 -3.42924386e-01\n",
      " -7.41171688e-02 -5.91881812e-01 -1.17196046e-01  1.10859618e-01\n",
      "  4.60051388e-01 -7.59188384e-02  1.09653864e-02  2.71522284e-01\n",
      "  1.58320820e+00 -2.77270615e-01  2.60630190e-01 -9.26536843e-02\n",
      " -6.31579936e-01 -4.80973780e-01 -2.34228238e-01 -1.36555195e-01\n",
      " -7.52016157e-02  3.47359449e-01  4.38224256e-01 -5.56504846e-01\n",
      " -6.62249148e-01 -1.54847369e-01  2.17475370e-01 -6.12219691e-01\n",
      " -2.03210965e-01 -6.58081353e-01  2.02743575e-01 -1.17175944e-01\n",
      " -3.25366795e-01  3.82234424e-01  1.25574619e-01 -9.28013548e-02\n",
      " -5.09264886e-01  7.43877709e-01 -1.79715995e-02 -3.03025931e-01\n",
      "  6.76051676e-01 -1.52958736e-01 -1.15945853e-01 -4.17601913e-01\n",
      "  1.71221241e-01 -2.80656427e-01 -2.51364380e-01 -1.88459828e-01\n",
      " -6.43782467e-02  5.60755670e-01 -4.04255129e-02  5.92037559e-01\n",
      "  5.03858149e-01 -6.67784456e-03 -4.56941068e-01 -9.39093754e-02\n",
      " -6.35886073e-01  7.02556893e-02 -2.14889124e-01 -6.08722344e-02\n",
      "  3.90269130e-01  1.23887740e-01  9.55620408e-02 -3.30613524e-01\n",
      "  9.62329209e-01 -4.50210631e-01 -3.39394301e-01  4.03706223e-01\n",
      " -2.50117093e-01 -4.51940268e-01 -7.77429998e-01 -4.47956622e-02\n",
      " -2.04467982e-01 -5.45866907e-01  1.43026307e-01 -5.70546210e-01\n",
      " -2.63803780e-01  1.84726849e-01  5.11115968e-01 -9.16490033e-02\n",
      " -1.49584815e-01  2.84477323e-01  2.60606140e-01 -1.53938279e-01\n",
      " -2.07396165e-01 -7.03126013e-01  1.18638672e-01  1.94827288e-01\n",
      " -3.68291378e-01 -1.61948547e-01 -3.23405594e-01  3.33069175e-01\n",
      "  6.15314603e-01  1.35412782e-01 -2.43353203e-01 -3.05064142e-01\n",
      " -2.49675170e-01  5.13273597e-01 -3.95629793e-01 -4.72845286e-01\n",
      " -5.71870446e-01  1.53715923e-01 -5.98493040e-01 -1.30517691e-01]\n",
      "\n",
      "Sentence: fever, headache from last 3 days\n",
      "Embedding: [-4.84745353e-01 -6.48535609e-01 -1.87531069e-01  1.77097723e-01\n",
      "  7.55117178e-01  1.16965570e-01 -2.02440560e-01 -1.56413808e-01\n",
      " -1.60799667e-01 -6.18981481e-01 -8.58784616e-02  2.48149130e-02\n",
      "  1.67751431e-01 -1.49504125e-01 -2.96767019e-02 -1.14527784e-01\n",
      " -2.88657285e-02 -7.39830136e-01 -1.48464084e-01 -1.76720366e-01\n",
      " -6.72854185e-01  3.36436480e-01 -4.12125766e-01  1.24274969e-01\n",
      "  1.92908466e-01  5.31422257e-01  5.78348577e-01 -2.08844244e-01\n",
      " -2.48969853e-01  9.30001810e-02  2.03744784e-01 -5.02680957e-01\n",
      " -4.60726112e-01 -1.23393208e-01  5.48512220e-01  3.83913875e-01\n",
      " -2.12472856e-01  6.04827255e-02 -1.41742572e-01  8.65526438e-01\n",
      " -3.71663064e-01  1.58780620e-01 -7.07105026e-02 -6.45660996e-01\n",
      "  1.43837467e-01  7.81613767e-01 -3.21128398e-01  4.19947267e-01\n",
      "  7.40284085e-01  3.92652780e-01 -7.24501312e-01 -5.60468912e-01\n",
      " -8.46665446e-03  6.88660562e-01 -9.26504806e-02  6.18295744e-02\n",
      " -5.22010744e-01  3.11923712e-01 -9.48934138e-01  5.61461210e-01\n",
      " -2.72118956e-01 -1.50307924e-01  7.05035448e-01 -1.73452690e-01\n",
      "  6.55435681e-01 -4.77998257e-01 -2.09408671e-01 -3.33370864e-01\n",
      "  6.67849660e-01  4.70382839e-01  1.48637295e-01  2.11353183e-01\n",
      " -5.67864537e-01 -4.31973875e-01  1.21007070e-01 -3.12060475e-01\n",
      "  9.73113552e-02 -3.57800543e-01  8.31821747e-03  3.94194275e-02\n",
      "  1.35450661e-01  6.03202283e-01  9.10752267e-02  4.19229269e-01\n",
      " -8.11092108e-02 -3.30458641e-01 -2.12269187e-01  4.54762727e-01\n",
      " -3.02422971e-01  1.09681234e-01  5.78974843e-01  1.49618257e-02\n",
      "  6.49473593e-02 -6.79076761e-02  4.87368166e-01  8.31842721e-02\n",
      " -2.37899706e-01  4.10498202e-01 -2.13720024e-01  3.80805463e-01\n",
      " -2.62365133e-01 -7.21171141e-01 -6.56876922e-01  2.88820803e-01\n",
      "  4.73006666e-01  4.74504143e-01  5.77433169e-01 -9.33549702e-02\n",
      " -2.45267764e-01 -4.49846387e-01 -4.77147922e-02  4.39038157e-01\n",
      "  8.04402009e-02 -2.95013577e-01  4.70785908e-02 -1.48282200e-02\n",
      " -1.70778915e-01  1.14537902e-01 -2.86532402e-01  4.99936521e-01\n",
      "  1.75519496e-01  4.19747502e-01  1.60442546e-01 -3.66897374e-01\n",
      "  4.34486508e-01  4.39253807e-01  3.63731325e-01 -5.00153713e-02\n",
      "  2.01479733e-01 -5.25500029e-02  1.15976728e-01 -4.49869335e-02\n",
      " -1.69090807e-01  2.63607144e-01 -6.19230941e-02  1.56881064e-01\n",
      "  2.92655975e-01  9.63718593e-02  3.05206686e-01 -7.24506080e-02\n",
      " -2.63254464e-01 -2.86862671e-01 -7.57393122e-01 -3.68813038e-01\n",
      "  5.51012993e-01 -1.27669156e-01  2.36020148e-01 -2.56548166e-01\n",
      "  7.39711225e-02 -1.00039053e+00  4.67531681e-02  1.50869802e-01\n",
      "  1.04821317e-01  6.79435790e-01  2.86343098e-01  2.58168668e-01\n",
      " -6.37527704e-02 -8.38958542e-04  3.58866096e-01 -3.00254941e-01\n",
      " -7.15020895e-02  9.15547833e-02 -3.61075670e-01  2.11099088e-01\n",
      "  1.73674658e-01  2.54195422e-01 -2.86662281e-02  2.57909954e-01\n",
      " -3.91329825e-02  3.06384891e-01 -5.07739782e-01  3.90970055e-03\n",
      " -1.88176498e-01  3.78450125e-01  7.23750144e-03  4.56720501e-01\n",
      " -2.33369455e-01 -4.84463632e-01  2.24318713e-01 -3.45343292e-01\n",
      "  1.25667119e+00  6.34062439e-02  5.72775416e-02  8.17882717e-01\n",
      "  4.81830597e-01 -1.42914250e-01  5.42909622e-01  4.12402004e-01\n",
      " -2.14219391e-01 -5.49626589e-01 -3.25322270e-01 -3.78314465e-01\n",
      "  2.37239197e-01  4.47760046e-01 -2.53632870e-02  1.00280695e-01\n",
      " -6.16312861e-01 -3.98697793e-01  2.19975635e-01  1.25420131e-02\n",
      " -1.60121918e-01  3.39838535e-01 -4.79234427e-01  1.96336165e-01\n",
      "  3.28627229e-01 -4.79837686e-01 -1.24523401e-01 -4.59805489e-01\n",
      " -3.92110705e-01 -2.63715774e-01  5.22290945e-01  1.11267853e+00\n",
      "  7.63777435e-01 -1.44762732e-02  1.76742971e-01  8.24157298e-02\n",
      " -3.56153607e-01 -1.55595511e-01 -1.76922660e-02  3.69947761e-01\n",
      " -1.27211556e-01  2.27289982e-02 -5.14428377e-01 -2.00465411e-01\n",
      " -1.07638603e-02  2.03452297e-02 -6.28786802e-01  2.18102764e-02\n",
      "  3.10620606e-01  1.19053178e-01 -3.52922440e-01  1.70297313e+00\n",
      "  4.58152331e-02  2.79209495e-01  6.15419567e-01 -6.03146434e-01\n",
      " -7.09191084e-01 -1.67487219e-01  4.67559755e-01  6.18123710e-01\n",
      "  1.65212885e-01  1.94758087e-01 -2.28987373e-02  2.66895205e-01\n",
      " -3.58990312e-01  3.74474436e-01 -3.57619792e-01 -3.71424764e-01\n",
      " -1.54765800e-01  1.11126699e-01  2.15163410e-01 -3.73147607e-01\n",
      " -5.25190055e-01 -3.14789265e-01  1.09228767e-01  2.03660518e-01\n",
      " -1.15968786e-01 -1.99940175e-01  8.02612677e-02  5.33041656e-01\n",
      " -1.21995345e-01 -3.60807866e-01 -1.88498676e-01 -3.67775746e-02\n",
      "  1.22326836e-01  4.79671597e-01  9.23648417e-01  9.42880213e-02\n",
      " -1.78236291e-01  6.46352589e-01 -2.05089703e-01 -4.67030644e-01\n",
      " -2.99350098e-02  8.59059393e-01 -8.26996565e-02 -5.63718557e-01\n",
      " -1.75387591e-01  4.07550007e-01  2.28754189e-02 -8.23287964e-01\n",
      " -2.95205414e-01 -8.06925893e-01 -8.55642930e-02 -3.64985645e-01\n",
      " -2.65592068e-01 -8.13781261e-01 -1.84295420e-02 -2.41300657e-01\n",
      "  5.54206789e-01  1.14987426e-01 -6.76345527e-02 -1.00652434e-01\n",
      "  1.37485802e+00 -4.86632496e-01  3.07805598e-01 -9.07076076e-02\n",
      " -1.09221315e+00 -2.12535232e-01 -8.97827670e-02 -2.62120694e-01\n",
      " -4.89248127e-01  4.46985096e-01  3.17017436e-01 -4.59798932e-01\n",
      " -1.86140373e-01 -2.07711592e-01  3.27737331e-01 -5.55220723e-01\n",
      " -5.10172129e-01 -3.42417151e-01  1.18113279e-01 -2.41010293e-01\n",
      " -3.05971414e-01 -6.09123111e-02  2.05399349e-01 -1.42131373e-01\n",
      " -2.69991308e-01  6.67902946e-01  2.14308083e-01 -1.84483632e-01\n",
      "  8.64061773e-01 -7.95044228e-02 -5.26021533e-02 -3.48909974e-01\n",
      "  3.70874926e-02 -3.53160143e-01 -4.19974953e-01  1.31382391e-01\n",
      " -5.44507988e-02  3.99173826e-01  8.08172151e-02  5.61802506e-01\n",
      "  5.66240609e-01 -9.77393538e-02 -5.69139242e-01  3.64438561e-03\n",
      " -3.38648796e-01  1.26682669e-01  5.83886318e-02 -4.66687679e-01\n",
      "  3.84231240e-01  3.65566134e-01  2.24984333e-01 -2.90628225e-01\n",
      "  9.43084180e-01 -4.72024409e-03  1.72864661e-01  3.94427419e-01\n",
      " -3.70456338e-01 -5.61080277e-01 -6.23900652e-01  1.07526131e-01\n",
      " -2.04017665e-02 -4.76863325e-01 -3.99659276e-01 -6.86795771e-01\n",
      " -2.25713909e-01  2.42213517e-01  6.26861811e-01 -1.57068506e-01\n",
      " -1.80216372e-01  1.57175183e-01  1.80804044e-01  8.48109052e-02\n",
      " -2.17540428e-01 -8.03062916e-01  5.01254527e-03  2.26220265e-01\n",
      " -9.25515369e-02 -4.52559739e-02 -1.66878283e-01  1.86903998e-01\n",
      "  5.52545547e-01  4.39796597e-01  7.11007565e-02 -3.81375462e-01\n",
      " -1.12294517e-01  4.07860816e-01 -2.01198101e-01 -7.32804954e-01\n",
      " -3.35635066e-01  8.69134814e-02 -5.07472038e-01  2.21117660e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sentence Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# The sentences we'd like to encode\n",
    "sentences = ['cough 15 days',\n",
    "    'cough and cold 15 days',\n",
    "    'cough since 15 days']\n",
    "sentences = ['fever headache for 20 days',\n",
    "    'fever and headache 1 day',\n",
    "    'fever, headache from last 3 days']\n",
    "# Get embeddings of sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing of 1st with 2nd :-> 0.8381\n",
      "comparing of 1st with 3rd :-> 0.8389\n",
      "comparing of 3rd with 2nd :-> 0.8559\n"
     ]
    }
   ],
   "source": [
    "#Semantic Textual Similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Download model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# The sentences we'd like to compute similarity about\n",
    "sentences = ['fever headache for 20 days',\n",
    "    'fever and headache 1 day',\n",
    "    'fever, headache from last 3 days']\n",
    "# sentences = ['cough 15 days',\n",
    "#     'cough and cold 15 days',\n",
    "#     'cough since 15 days']\n",
    "\n",
    "# Get embeddings of sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compute similarities\n",
    "sim = util.cos_sim(embeddings[0], embeddings[1])\n",
    "print(\"comparing of 1st with 2nd :->\",\"{0:.4f}\".format(sim.tolist()[0][0])) \n",
    "sim = util.cos_sim(embeddings[0], embeddings[2])\n",
    "print(\"comparing of 1st with 3rd :->\",\"{0:.4f}\".format(sim.tolist()[0][0])) \n",
    "sim = util.cos_sim(embeddings[-1], embeddings[1])\n",
    "print(\"comparing of 3rd with 2nd :->\",\"{0:.4f}\".format(sim.tolist()[0][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JONES\n"
     ]
    }
   ],
   "source": [
    "#Word correction\n",
    "from textblob import Word\n",
    "\n",
    "\n",
    "def correct_word_spelling(word):\n",
    "    \n",
    "    word = Word(word)\n",
    "    \n",
    "    result = word.correct()\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "\n",
    "correct_word_spelling('JONES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones\n"
     ]
    }
   ],
   "source": [
    "#Sectence Correction\n",
    "sentence = 'JONES'\n",
    "sentence = sentence.lower()\n",
    "sentence = TextBlob(sentence)\n",
    "result = sentence.correct()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S No  Symptoms\n",
       "0    False     False\n",
       "1    False     False\n",
       "2    False     False\n",
       "3    False     False\n",
       "4    False     False\n",
       "..     ...       ...\n",
       "995  False     False\n",
       "996  False     False\n",
       "997  False     False\n",
       "998  False     False\n",
       "999  False     False\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>defacation</th>\n",
       "      <td>0.808049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>0.481299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>0.339717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orally</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eruption</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essential</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrs</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>855 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "defacation  0.808049\n",
       "on          0.481299\n",
       "pain        0.339717\n",
       "02          0.000000\n",
       "orally      0.000000\n",
       "...              ...\n",
       "eruption    0.000000\n",
       "essential   0.000000\n",
       "et          0.000000\n",
       "eval        0.000000\n",
       "yrs         0.000000\n",
       "\n",
       "[855 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(df['Symptoms'].values.astype('U'))\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names(),columns=[\"idf_weights\"])\n",
    "\n",
    "\n",
    "#inverse document frequency\n",
    "df_idf.sort_values(by=['idf_weights'])\n",
    "\n",
    "#tfidf\n",
    "tf_idf_vector=tfidf_transformer.transform(word_count)\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "first_document_vector=tf_idf_vector[1]\n",
    "df_tfifd= pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "\n",
    "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#nltk.download('pos_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pain', 'NN'), ('abdomen', 'NNS'), ('u/e', 'VBP')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"pain abdomen u/e\"\n",
    "# Tokenize to words\n",
    "words = word_tokenize(text)\n",
    "# POS tag the words\n",
    "words_tagged = pos_tag(words)\n",
    "words_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple grammar to create tree\n",
    "grammar = \"NP: {<JJ><NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S pain/NN abdomen/NNS u/e/VBP)\n"
     ]
    }
   ],
   "source": [
    "# Create tree\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "tree = parser.parse(words_tagged)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\huggingface_hub\\file_download.py:563: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-18 11:09:46,700 loading file C:\\Users\\Admin\\.flair\\models\\pos-english\\a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
      "2022-07-18 11:09:47,799 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\huggingface_hub\\file_download.py:563: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-18 11:09:49,075 loading file C:\\Users\\Admin\\.flair\\models\\ner-english\\4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2022-07-18 11:09:56,527 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import MultiTagger\n",
    "\n",
    "\n",
    "sentence = 'RIGHT KNEE PAIN UNDER EVALUATION'.lower()\n",
    "# make a sentence\n",
    "sentence = Sentence(sentence)\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = MultiTagger.load(['pos', 'ner'])\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"right\" → UH (0.8504)\n",
      "Token[1]: \"knee\" → NN (0.9914)\n",
      "Token[2]: \"pain\" → NN (1.0)\n",
      "Token[3]: \"under\" → IN (1.0)\n",
      "Token[4]: \"evaluation\" → NN (1.0)\n"
     ]
    }
   ],
   "source": [
    "for label in sentence.get_labels('pos'):\n",
    "    print(label)\n",
    "\n",
    "for label in sentence.get_labels('ner'):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "sentence = Sentence('abscess present over right gluteal region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-18 11:10:53,987 loading file C:\\Users\\Admin\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  ['Sentence: \"abscess present over right gluteal region\"'/'NEGATIVE' (0.9996)]\n"
     ]
    }
   ],
   "source": [
    "classifier.predict(sentence)\n",
    "\n",
    "print('Sentiment: ', sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2890834248.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8244\\2890834248.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    probab_word_1 = word_list[word_list[]]\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Probabilistic Model\n",
    "# word_1 = 'pain'\n",
    "# word_2 = 'abdomen'\n",
    "# probab_word_1 = word_list[word_list[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\"\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a string\n",
    "sentence = Sentence('The grass is green.')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "Token[1]: \"grass\"\n",
      "Token[2]: \"is\"\n",
      "Token[3]: \"green\"\n",
      "Token[4]: \".\"\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scispacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token          | pos   | label  | parent  \n",
      "pyruvoyl-tetrahydropterin| NOUN  | ENTITY | deficiency\n",
      "synthase       | NOUN  | ENTITY | deficiency\n",
      "deficiency     | NOUN  | ENTITY | deficiency\n"
     ]
    }
   ],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "doc = nlp(\"pyruvoyl-tetrahydropterin synthase deficiency\")\n",
    "fmt_str = \"{:<15}| {:<6}| {:<7}| {:<8}\"\n",
    "print(fmt_str.format(\"token\", \"pos\", \"label\", \"parent\"))\n",
    "for token in doc:\n",
    "    print(fmt_str.format(token.text, token.pos_, token.ent_type_, token.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_sm-0.5.0.tar.gz\n",
    "#%pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bionlp13cg_md-0.5.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_ner_bionlp13cg_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token          | pos   | label  | parent  \n",
      "Acute          | ADJ   |        | Intermittent\n",
      "Intermittent   | ADJ   |        | Porphyria\n",
      "Porphyria      | PROPN |        | Porphyria\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "doc = nlp(\"Acute Intermittent Porphyria\")\n",
    "fmt_str = \"{:<15}| {:<6}| {:<7}| {:<8}\"\n",
    "print(fmt_str.format(\"token\", \"pos\", \"label\", \"parent\"))\n",
    "for token in doc:\n",
    "    print(fmt_str.format(token.text, token.pos_, token.ent_type_, token.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short | Long                          | Starts| Ends  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\scispacy\\abbreviation.py:230: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  global_matches = self.global_matcher(doc)\n"
     ]
    }
   ],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "#nlp = spacy.load(\"en_core_sci_sm\")\n",
    "# Add the abbreviation pipe to the spacy pipeline.\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "doc = nlp(\n",
    "    \"AIP with something unclear\"\n",
    ")\n",
    "fmt_str = \"{:<6}| {:<30}| {:<6}| {:<6}\"\n",
    "print(fmt_str.format(\"Short\", \"Long\", \"Starts\", \"Ends\"))\n",
    "for abrv in doc._.abbreviations:\n",
    "    print(fmt_str.format(abrv.text, str(abrv._.long_form), abrv.start, abrv.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\scispacy\\candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\scispacy\\candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity              | Concept ID | Score \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8244\\2689367772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfmt_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{:<20}| {:<11}| {:<6}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Entity\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Concept ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkb_entry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkb_ents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcui\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkb_entry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "from scispacy.linking import EntityLinker\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "nlp.add_pipe(\"scispacy_linker\", config={\"linker_name\": \"umls\", \"max_entities_per_mention\": 6})\n",
    "doc = nlp(\"adenosquamous carcinoma(Gollbladder)\")\n",
    "fmt_str = \"{:<20}| {:<11}| {:<6}\"\n",
    "print(fmt_str.format(\"Entity\", \"Concept ID\", \"Score\"))\n",
    "entity = doc.ents[2]\n",
    "for kb_entry in entity._.kb_ents:\n",
    "    cui = kb_entry[0]\n",
    "    match_score = kb_entry[1]\n",
    "    print(fmt_str.format(entity.text, cui, match_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install neuspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder is set to `C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\../data` script\n"
     ]
    }
   ],
   "source": [
    "import neuspell\n",
    "from neuspell import BertChecker, CnnlstmChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "is_module_available() missing 1 required positional argument: 'module_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1092\\1932054110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\" see available checkers \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"available checkers: {neuspell.is_module_available()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: is_module_available() missing 1 required positional argument: 'module_name'"
     ]
    }
   ],
   "source": [
    "import neuspell\n",
    "from neuspell import is_module_available, BertChecker\n",
    "\n",
    "\"\"\" see available checkers \"\"\"\n",
    "print(f\"available checkers: {neuspell.available_checkers()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install neuspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gok REIT Scovell overboard inspectors precursor trawler Beedle Weinsteins blighted Asbo Dancer Gurrolla Fehrenbach blinking stringently Berezovsky Gurrolla flagstones immunology dunks TAKES Shands Rater Bergamasco Gurrolla lionized colleges inverter']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker_bert.correct_strings([\"Thee wors are often used together. You can go to the defition of spellig or the defintion of mistae. Or, see other combintions with mistke.\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocab from path:C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\../data/checkpoints/subwordbert-probwordnoise\\vocab.pkl\n",
      "initializing model\n",
      "SubwordBert(\n",
      "  (bert_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bert_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=100002, bias=True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "185211810\n",
      "loading pretrained weights from path:C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\../data/checkpoints/subwordbert-probwordnoise\n",
      "Loading model params from checkpoint dir: C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\../data/checkpoints/subwordbert-probwordnoise\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '<'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1092\\1403025330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m\"\"\" load spell checkers \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mchecker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;34m\"\"\" spell correction \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\corrector_subwordbert.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(self, ckpt_path, vocab, weights)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"loading pretrained weights from path:{self.weights_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\neuspell\\seq_modeling\\subwordbert.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[1;34m(model, checkpoint_path, optimizer, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mmap_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loading model params from checkpoint dir: {checkpoint_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcheckpoint_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model.pth.tar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;31m# print(f\"previously model saved at : {checkpoint_data['epoch_id']}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    918\u001b[0m             \"functionality.\")\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m     \u001b[0mmagic_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '<'."
     ]
    }
   ],
   "source": [
    "from neuspell import BertChecker\n",
    "\n",
    "\"\"\" load spell checkers \"\"\"\n",
    "checker = BertChecker()\n",
    "checker.from_pretrained()\n",
    "\n",
    "\"\"\" spell correction \"\"\"\n",
    "checker.correct(\"I luk foward to receving your reply\")\n",
    "# → \"I look forward to receiving your reply\"\n",
    "checker.correct_strings([\"I luk foward to receving your reply\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leg', 'stage', 'peg', 'ramification', 'wooden_leg', 'branch', 'pegleg'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"leg\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "\n",
    "print(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install contextualSpellCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "doc = nlp('INCREASED FREQUENCY OF MICTURATION SINCE 20 DAYS')\n",
    "\n",
    "print(doc._.performed_spellCheck) #Should be True\n",
    "print(doc._.outcome_spellCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
